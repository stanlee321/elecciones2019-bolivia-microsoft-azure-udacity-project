# Computer Vision for automate the process of Elections

The intention of this work is to automate the counting of votes in the electoral records. Computer vision techniques are used to attempt to read the regions of interest and subsequently read the handwritten numbers within these regions of interest. The dataset that is accessed comes from the Bolivian elections 2019. Within this dataset whose size is 60 GB. We only worked on the images that were scanned since they are easier to process due to the computer vision agorithm that was developed. A work that is left as a potential research area is to use the labels generated by the computer vision algorithm, create a VOC like dataset and train an Object Detection model, the latter was completed but with poor results in a first iteration.


## Download the dataset.

To download the dataset of the images, the jupyter notebook called `DOWNLOAD_DATASET/Download_images_azure.ipynb` is used. This notebook downloads the 60 GB of information, whose categories are the following.

### uploadedimages

This images comes from a direct photo from a smartphone taked the moment where the operator in charge of the elections table must to send this report for fast counts called "TREP"


<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/DOWNLOAD_DATASET/dataset_uploadedimages.png" /></div>


### uploadedimagescomputo

This images are the same from `uploadedimages`(TREP) but are been scanned. We take this set of images (~30GB)  for our Computer Vision work pipeline.

<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/DOWNLOAD_DATASET/dataset_uploadedimagescomputo.png" /></div>


### imgactastrep

This set of images are been flaged as **fraudulent** by the original team that work with this images the last year, this set of images comes from the `uploadedimages` set.

<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/DOWNLOAD_DATASET/dataset_imgactastrep.png" /></div>


## Create VOC like dataset.


###  Target Dataset

We take the `uploadedimagescomputo` set of images since this are more easy to work with Computer Vision techniques.
One example of this dataset set is this image.

<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/DOWNLOAD_DATASET/102051.jpg" /></div>

Using Canny edge detection and other simple computer vision techinques we can start to get some detection of the areas of interest.


<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/DOWNLOAD_DATASET/h_res3.png" /></div>


Into this image we are only interested in  detecting this region of the image.

<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/DOWNLOAD_DATASET/fff888b3-f7d0-11e9-800f-c8ff28027534.jpg
" /></div>


Other parts of the image also can be used for another kind of applications, like "fingerprint" maching across the whole dataset or  read and detect duplicate names in the region of people in charge of the election table.

This time we are only interested in counting the votes in this selected Region of Interest.

###  Creation of VOC Like dataset


For create this dataset we create all the steps for this into the file `VOC_CREATION/bounding_boxes_creation.py`.

With a simple.

```terminal

cd VOC_CREATION

python bounding_boxes_creation.py --data_path=$UPLOADED_IMAGES_COMPUTO
```

Will start to create the dataset, into a default folder called `results/`.

We made use of an env variable `$UPLOADED_IMAGES_COMPUTO` for set the directory of the target images.

The result is  a set if croped images in `VOC_CREATION/results/Train/images` and his  XML labels  `VOC_CREATION/results/Train/labels`. ~21000 in total.

<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/VOC_CREATION/dataset_voc_train.png" /></div>

A sample with bounding boxes drawing this this.
<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/VOC_CREATION/1da06fc2-f7de-11e9-b23f-c8ff28027534.jpg" /></div>



The total success of detected boxes with the simple computer vision algorithm is aprox. `~(21000/31000 )*100  ~= 68 %`.
We made a try to fine tune a object detection model for increase this number and read more electoral papers.

### Attempt to finetune SSD MobilenetV2 with this VOC dataset.

### Create TF-RECORDS FILE

We convert to tf-records format our VOC dataset using the script in `VOC_CREATION/create_tf_records.py`

### Retrain the model

For fast iteration around this problem we use the MONK `https://github.com/Tessellate-Imaging/Monk_Object_Detection` library for retrain object detection models. The fork of his notebook called `Train Without Validation Dataset.ipynb` is in our folder called `OBJECT_DETECTION/Train_Without_Validation_Dataset.ipynb`.
We had a problem with our credit card and we are unnable to open an azure account and train the model inside azure compute instances. For this reason we made use of google colab, we use a lot of GPU VRAM for finetune the mobilenetv2 model. The result of this finetuning is .

<div style="text-align:center"><img src ="https://raw.githubusercontent.com/stanlee321/elecciones2019-bolivia-microsoft-azure-udacity-project/master/OBJECT_DETECTION/result_object_detection.jpeg" /></div>

We think that the MONK library is not resizing correctly our image in this high level interface

We have not enought time for test the native tensorflow object detection library or another models, by this reason we leave this approach for get to work the remaining 32% of the images.

## Count of votes.

Since we labeled our Regions of Interest, we can start to count the numbers inside the boxes with another bit of work of computer vision.


WORK IN PROGRES...

